{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise18_03.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37vrnAFPW6_C",
        "colab_type": "text"
      },
      "source": [
        "#Exercise 2: Adding Data Processing steps into Web API\n",
        "In this exercise, we will save the parameters used for processing the training dataset and reuse them on the API to perform the same data transformation steps before getting a prediction.\n",
        "\n",
        "Note\n",
        "The dataset used for this exercise is the Breast Cancer Detection shared by Dr. WIlliam H. Wolberg from the University of Wisconsin Hospitals and the attribute information can be found here - https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)\n",
        "\n",
        "The dataset can also be found in our repository here - https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter11/dataset/breast-cancer-wisconsin.data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ox-pHUPX78-",
        "colab_type": "text"
      },
      "source": [
        "1. Open on a new Colab notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjLQtyoWtL3r",
        "colab_type": "text"
      },
      "source": [
        "2. Import the packages pandas and joblib, RandomForestClassifier from sklearn.ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_b0A-ElAnHj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJMbepT9tKZx",
        "colab_type": "text"
      },
      "source": [
        "3. Assign the link to the Breast Cancer dataset to a variable called 'file_url'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuyNn2VlnHm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_url = 'https://raw.githubusercontent.com/PacktWorkshops/The-Data-Science-Workshop/master/Chapter11/dataset/breast-cancer-wisconsin.data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ynp0SKltKFf",
        "colab_type": "text"
      },
      "source": [
        "4. Create a list called 'col_names' with the following names: 'Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size',\n",
        "'Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSH55O2Qn3nn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "col_names = ['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size',\n",
        "'Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V_NRU5gtJje",
        "colab_type": "text"
      },
      "source": [
        "5. Load the dataset into DataFrame using pd.read_csv() with the follwong parameters: header=None, names=col_names, na_values='?'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHM7W8jTnHye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(file_url, header=None, names=col_names, na_values='?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4TKpjV87TtB",
        "colab_type": "text"
      },
      "source": [
        "6. Extract the response variable 'Class' using the method .pop()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOV3ihu0dnnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df.pop('Class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ7WhJJx7TOI",
        "colab_type": "text"
      },
      "source": [
        "7. Remove the column 'Sample code number' from the DataFrame using the method .drop() with axis=1 as parameter to specify we are dropping columns and not rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnADQ-gGfGk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop('Sample code number', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qbiSWpI7UOC",
        "colab_type": "text"
      },
      "source": [
        "8. Create a variable called 'training_rows' that will contain the number of rows that corresponds to 70% of the records."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtp9sRXbdnpx",
        "colab_type": "code",
        "outputId": "7e8d1e4f-90c1-4598-ebec-fedb53c196d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "training_rows = int(df.shape[0] * 0.7)\n",
        "training_rows"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "489"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZXNVLZc7Uz3",
        "colab_type": "text"
      },
      "source": [
        "9. Split the dataframes df and y into training and test sets using 'training_rows' as the threshold for the split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QiCAi94dnsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df[:training_rows]\n",
        "y_train = y[:training_rows]\n",
        "X_test = df[training_rows:]\n",
        "y_test = y[training_rows:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js5km2e97VQ6",
        "colab_type": "text"
      },
      "source": [
        "10. Calculate the number of missing values for each column by combining the methods .isna() with .sum()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APxUiwuLdnzH",
        "colab_type": "code",
        "outputId": "027cec04-f4c0-4364-fcfc-d2f9048e946f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "X_train.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Clump Thickness                 0\n",
              "Uniformity of Cell Size         0\n",
              "Uniformity of Cell Shape        0\n",
              "Marginal Adhesion               0\n",
              "Single Epithelial Cell Size     0\n",
              "Bare Nuclei                    15\n",
              "Bland Chromatin                 0\n",
              "Normal Nucleoli                 0\n",
              "Mitoses                         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5T5rPaK7VvG",
        "colab_type": "text"
      },
      "source": [
        "11. Extract the list of columns that are not of type 'object' and save the result in a variable called 'num_columns'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChSTYAQHdn16",
        "colab_type": "code",
        "outputId": "5993c63f-72e3-4106-87cc-2672ef748ffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "num_columns = [col for col in X_train.columns if X_train[col].dtype != 'object']\n",
        "num_columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Clump Thickness',\n",
              " 'Uniformity of Cell Size',\n",
              " 'Uniformity of Cell Shape',\n",
              " 'Marginal Adhesion',\n",
              " 'Single Epithelial Cell Size',\n",
              " 'Bare Nuclei',\n",
              " 'Bland Chromatin',\n",
              " 'Normal Nucleoli',\n",
              " 'Mitoses']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6q01y1v7WUs",
        "colab_type": "text"
      },
      "source": [
        "12. Create an empty dictionary called 'column_mean', iterate through the list 'num_columns' and for each column add the column name and its average value to this dictionary and display its content."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3rO4euNekF3",
        "colab_type": "code",
        "outputId": "a97f2397-16a3-4b86-f7d8-46cb0f0135a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "column_mean = {}\n",
        "for col in num_columns:\n",
        "  column_mean[col] = X_train[col].mean()\n",
        "column_mean"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Bare Nuclei': 4.0042194092827,\n",
              " 'Bland Chromatin': 3.61758691206544,\n",
              " 'Clump Thickness': 4.644171779141105,\n",
              " 'Marginal Adhesion': 2.9529652351738243,\n",
              " 'Mitoses': 1.7198364008179958,\n",
              " 'Normal Nucleoli': 3.1533742331288344,\n",
              " 'Single Epithelial Cell Size': 3.462167689161554,\n",
              " 'Uniformity of Cell Shape': 3.4478527607361964,\n",
              " 'Uniformity of Cell Size': 3.347648261758691}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Juck4SQ7Wzb",
        "colab_type": "text"
      },
      "source": [
        "13. Import the pickle package and save 'column_mean' into a file called 'columns_mean.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNPAWdnNe_ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(column_mean, open(\"columns_mean.pkl\", \"wb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCMLXpDv7Xal",
        "colab_type": "text"
      },
      "source": [
        "14. Iterate through the list 'num_columns' and for each column, replace missing values by the relevant average contained in the 'column_mean' dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1vXPXzie_rt",
        "colab_type": "code",
        "outputId": "de376446-4573-4c28-9ee2-5304aefb503c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "for col in num_columns:\n",
        "  X_train[col].fillna(column_mean[col], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._update_inplace(new_data)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq4k91cQ7YXF",
        "colab_type": "text"
      },
      "source": [
        "15. Instanciate a RandomForestClassifier with random_state=1 and train it with the training sets using the .fit() method. Save the model into a file called 'model.pkl' using the moethod joblib.dump()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkFwEdz-ficr",
        "colab_type": "code",
        "outputId": "9917f8de-6fb7-456b-cab7-ed2bbf9564e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "rf_model = RandomForestClassifier(random_state=1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "joblib.dump(rf_model, \"model.pkl\") "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xfmSkKk7ZfO",
        "colab_type": "text"
      },
      "source": [
        "16. Import the socket, threading, requests, json and numpy packages and the classes Flask, jsonify and request from the package flask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E2YdRNef1eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import socket\n",
        "import threading\n",
        "import requests\n",
        "import json\n",
        "from flask import Flask, jsonify, request\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqkIFpLa7a2X",
        "colab_type": "text"
      },
      "source": [
        "17. Create a new Flask app and save it into a variable called 'app'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo2FtaYSf1kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "app = Flask(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l7i9ngX7bdv",
        "colab_type": "text"
      },
      "source": [
        "18. Load the pre-trained model from the file 'model.pkl' using joblib.load() and save it into a variable called 'trained_model'. Load the saved dictionary from 'columns_mean.pkl' using pickle.load() and save it into a variable called 'var_means'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ketUKpP0f1nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained_model = joblib.load(\"model.pkl\")\n",
        "var_means = pickle.load(open(\"columns_mean.pkl\", \"rb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynUVsuSy7b7D",
        "colab_type": "text"
      },
      "source": [
        "19. Create an API endpoint for the path 'api' that accepts only POST requests and will call a function called predict(). This function will read the JSON received using the method request.get_json(), transform it into a DataFrame, loop through all the items from 'var_means' and use its keys and values to replace missing value, predict the outcome with 'trained_model', convert the prediction from numpy array to string with array2string() and then to JSON with jsonify()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYSIZLGxf1pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@app.route('/api', methods=['POST'])\n",
        "def predict():\n",
        "  data = request.get_json()\n",
        "  df_test = pd.DataFrame(data, index=[0])\n",
        "  for col, avg_value in var_means.items():\n",
        "    df_test[col].fillna(avg_value, inplace=True)\n",
        "  prediction = trained_model.predict(df_test)\n",
        "  str_pred = np.array2string(prediction)\n",
        "  return jsonify(str_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc6ruISH7cYT",
        "colab_type": "text"
      },
      "source": [
        "20. Create a new thread for running your Flask app using the method threading.Thread with the following parameters: target=app.run, kwargs={'host':'0.0.0.0','port':80}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-8fz7aFf1jm",
        "colab_type": "code",
        "outputId": "a7efe4b6-207f-4804-8d9d-31c33fd00af3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "flask_thread = threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':80})\n",
        "flask_thread.start()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-6:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 990, in run\n",
            "    run_simple(host, port, self, **options)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/werkzeug/serving.py\", line 1010, in run_simple\n",
            "    inner()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/werkzeug/serving.py\", line 963, in inner\n",
            "    fd=fd,\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/werkzeug/serving.py\", line 806, in make_server\n",
            "    host, port, app, request_handler, passthrough_errors, ssl_context, fd=fd\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/werkzeug/serving.py\", line 699, in __init__\n",
            "    HTTPServer.__init__(self, server_address, handler)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 456, in __init__\n",
            "    self.server_bind()\n",
            "  File \"/usr/lib/python3.6/http/server.py\", line 136, in server_bind\n",
            "    socketserver.TCPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.6/socketserver.py\", line 470, in server_bind\n",
            "    self.socket.bind(self.server_address)\n",
            "OSError: [Errno 98] Address already in use\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d1_DUd87etf",
        "colab_type": "text"
      },
      "source": [
        "21. Convert the first record of X_test that has missing value on the column 'Bare Nuclei' and convert it into json format using the .to_json() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AF4eiCKugmZ1",
        "colab_type": "code",
        "outputId": "aca4100b-885f-409a-c837-95c338ecff5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "record = X_test[X_test['Bare Nuclei'].isna()].iloc[0].to_json()\n",
        "record"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"Clump Thickness\":1.0,\"Uniformity of Cell Size\":1.0,\"Uniformity of Cell Shape\":1.0,\"Marginal Adhesion\":1.0,\"Single Epithelial Cell Size\":1.0,\"Bare Nuclei\":null,\"Bland Chromatin\":1.0,\"Normal Nucleoli\":1.0,\"Mitoses\":1.0}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oadGSUEB7fQu",
        "colab_type": "text"
      },
      "source": [
        "22. Create a dictionary called headers with the following key-value pairs: 'content-type': 'application/json', 'Accept-Charset': 'UTF-8'. Extract into a new variable called 'ip_address' the IP address of the host using the methods socket.gethostname() and socket.gethostbyname()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GLgAVCTf1g3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headers = {'content-type': 'application/json', 'Accept-Charset': 'UTF-8'}\n",
        "ip_address = socket.gethostbyname(socket.gethostname())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eWDuO1t7fvR",
        "colab_type": "text"
      },
      "source": [
        "23. Send a HTTP POST request to the server using the method requests.post() with the HTTP url to the endpoint, record and headers as its parameters and print its .text attribute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR7wNIjkgmfa",
        "colab_type": "code",
        "outputId": "c3e82bb6-874f-45fc-b2b2-b151cf0d3ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "r = requests.post(f\"http://{ip_address}/api\", data=record, headers=headers)\n",
        "r.text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2 - - [06/Nov/2019 03:35:04] \"\u001b[37mPOST /api HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\"[2]\"\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQNRAQBGkHjP",
        "colab_type": "text"
      },
      "source": [
        "Excellent! We just deployed our pre-trained Machine Learning algorithm into a WeB API. In a real-world project, you will have to deploy it on separate server within your organisation and need to configure networking settings so that the authorised systems or services can send requests to this API."
      ]
    }
  ]
}